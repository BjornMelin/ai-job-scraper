# AI Job Scraper - Phase 1 Environment Configuration
# Copy this file to .env and update with your values

# =============================================================================
# CORE CONFIGURATION (Phase 1)
# =============================================================================

# OpenAI API Key (required for cloud fallback)
# Get this from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Token threshold for local/cloud routing (default: 8000)
# Requests above this will use cloud fallback
AI_TOKEN_THRESHOLD=8000

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# Database URL (default: sqlite:///jobs.db)
DATABASE_URL=sqlite:///jobs.db

# =============================================================================
# OPTIONAL CONFIGURATION
# =============================================================================

# Proxy configuration (leave empty if not using proxies)
# PROXY_POOL=["http://proxy1:port", "http://proxy2:port"]
# USE_PROXIES=false

# Observability (optional - requires Langfuse account)
# LANGFUSE_PUBLIC_KEY=your_public_key
# LANGFUSE_SECRET_KEY=your_secret_key

# =============================================================================
# REMOVED IN PHASE 1 (No longer needed)
# =============================================================================

# ❌ GROQ_API_KEY (replaced by unified LiteLLM routing)
# ❌ USE_GROQ (replaced by automatic routing)
# ❌ AI_LOCAL_TIMEOUT (handled by LiteLLM)
# ❌ AI_CLOUD_TIMEOUT (handled by LiteLLM)
# ❌ AI_MAX_CONNECTIONS (handled by LiteLLM)
# ❌ LOG_AI_ROUTING (handled by LiteLLM)
# ❌ ENABLE_CLOUD_FALLBACK (always enabled in Phase 1)