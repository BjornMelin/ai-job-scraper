# LiteLLM Configuration for AI Job Scraper
# ADR-011 Compliant Configuration
# Library-first implementation with zero custom routing

model_list:
  - model_name: local-qwen
    litellm_params:
      model: hosted_vllm/Qwen3-4B-Instruct-2507-FP8
      api_base: http://localhost:8000/v1
      api_key: EMPTY
      max_tokens: 2000
      timeout: 30
      
  - model_name: gpt-4o-mini
    litellm_params:
      model: gpt-4o-mini
      timeout: 30

litellm_settings:
  num_retries: 3
  timeout: 30
  fallbacks: [{"local-qwen": ["gpt-4o-mini"]}]
  context_window_fallbacks: [{"local-qwen": ["gpt-4o-mini"]}]